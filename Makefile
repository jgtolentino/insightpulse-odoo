# Makefile for InsightPulse Odoo
# Enterprise SaaS Replacement Suite

.PHONY: help init dev prod stop down logs test lint deploy-prod backup restore update-oca create-module shell psql clean up restart health validate validate-structure validate-makefile health-report

# Default target
.DEFAULT_GOAL := help

help: ## Show this help message
	@echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
	@echo "â•‘  InsightPulse Odoo - Enterprise SaaS Replacement Suite      â•‘"
	@echo "â•‘  Makefile Commands                                           â•‘"
	@echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
	@echo ""
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $$1, $$2}'
	@echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ SETUP & INITIALIZATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

init: ## Initialize project (first-time setup)
	@echo "ğŸš€ Initializing InsightPulse Odoo..."
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo "Step 1: Cloning OCA repositories..."
	@./scripts/setup/01-clone-oca-repos.sh || echo "âš ï¸  OCA repos script not found (will be created)"
	@echo ""
	@echo "Step 2: Installing dependencies..."
	@./scripts/setup/02-install-dependencies.sh || echo "âš ï¸  Dependencies script not found (will be created)"
	@echo ""
	@echo "Step 3: Setting up environment..."
	@if [ ! -f config/.env.dev ]; then \
		cp config/.env.example config/.env.dev 2>/dev/null || echo "POSTGRES_PASSWORD=odoo" > config/.env.dev; \
		echo "âœ… Created config/.env.dev"; \
	fi
	@echo ""
	@echo "Step 4: Creating required directories..."
	@mkdir -p backups data/demo logs
	@echo ""
	@echo "âœ… Initialization complete!"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo "Next: Run 'make dev' to start development environment"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ› ï¸ DEVELOPMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

dev: ## Start development environment
	@echo "ğŸ› ï¸  Starting development environment..."
	@if [ -f infrastructure/docker/docker-compose.yml ]; then \
		docker-compose -f infrastructure/docker/docker-compose.yml \
		               -f infrastructure/docker/docker-compose.dev.yml up -d; \
	else \
		docker-compose up -d; \
	fi
	@echo ""
	@echo "âœ… Development environment started!"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo "ğŸŒ Odoo:           http://localhost:8069"
	@echo "ğŸ“Š Superset:       http://localhost:8088"
	@echo "ğŸ”§ n8n:            http://localhost:5678"
	@echo "ğŸ” Authentik:      http://localhost:9000"
	@echo "ğŸ“¦ MinIO:          http://localhost:9001"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo "Credentials: admin / admin (change in production)"

up: dev ## Alias for 'make dev'

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ PRODUCTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

prod: ## Start production environment
	@echo "ğŸš€ Starting production environment..."
	@if [ -f infrastructure/docker/docker-compose.yml ]; then \
		docker-compose -f infrastructure/docker/docker-compose.yml \
		               -f infrastructure/docker/docker-compose.prod.yml up -d; \
	else \
		@echo "âš ï¸  Production docker-compose files not found"; \
		@echo "Using default docker-compose.yml..."; \
		docker-compose up -d; \
	fi
	@echo "âœ… Production environment started!"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ›‘ STOP & CLEANUP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

stop: ## Stop all services (preserve data)
	@echo "ğŸ›‘ Stopping all services..."
	@if [ -f infrastructure/docker/docker-compose.yml ]; then \
		docker-compose -f infrastructure/docker/docker-compose.yml down; \
	else \
		docker-compose down; \
	fi
	@echo "âœ… All services stopped (data preserved)"

down: stop ## Alias for 'make stop'

restart: ## Restart all services
	@echo "ğŸ”„ Restarting all services..."
	@make stop
	@sleep 2
	@make dev
	@echo "âœ… Services restarted!"

clean: ## Clean up (remove containers, volumes, and data) âš ï¸ DESTRUCTIVE
	@echo "âš ï¸  WARNING: This will DELETE all containers, volumes, and data!"
	@echo "Press Ctrl+C to cancel, or wait 5 seconds to continue..."
	@sleep 5
	@echo "ğŸ—‘ï¸  Cleaning up..."
	@if [ -f infrastructure/docker/docker-compose.yml ]; then \
		docker-compose -f infrastructure/docker/docker-compose.yml down -v; \
	else \
		docker-compose down -v; \
	fi
	@rm -rf backups/* logs/*
	@echo "âœ… Cleanup complete! All data deleted."

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‹ LOGS & MONITORING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logs: ## View logs (follow mode, all services)
	@if [ -f infrastructure/docker/docker-compose.yml ]; then \
		docker-compose -f infrastructure/docker/docker-compose.yml logs -f; \
	else \
		docker-compose logs -f; \
	fi

logs-odoo: ## View Odoo logs only
	@if [ -f infrastructure/docker/docker-compose.yml ]; then \
		docker-compose -f infrastructure/docker/docker-compose.yml logs -f odoo; \
	else \
		docker-compose logs -f odoo; \
	fi

logs-postgres: ## View PostgreSQL logs only
	@if [ -f infrastructure/docker/docker-compose.yml ]; then \
		docker-compose -f infrastructure/docker/docker-compose.yml logs -f postgres; \
	else \
		docker-compose logs -f postgres; \
	fi

health: ## Check health status of all services
	@echo "ğŸ¥ Checking service health..."
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@docker-compose ps
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¥ INSTANCE HEALTH CHECKS (Multi-Environment)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: instance-health instance-health-local instance-health-staging instance-health-production

instance-health: ## Check instance health (default: local environment)
	@echo "ğŸ¥ [instance-health] Checking default (local) environment"
	@bash scripts/health/check-instance-health.sh local

instance-health-local: ## Check local instance health (Odoo/Supabase/Superset)
	@echo "ğŸ¥ [instance-health-local] Checking local environment"
	@bash scripts/health/check-instance-health.sh local

instance-health-staging: ## Check staging instance health
	@echo "ğŸ¥ [instance-health-staging] Checking staging environment"
	@bash scripts/health/check-instance-health.sh staging

instance-health-production: ## Check production instance health
	@echo "ğŸ¥ [instance-health-production] Checking production environment"
	@bash scripts/health/check-instance-health.sh production

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª TESTING & QUALITY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

test: ## Run all tests
	@echo "ğŸ§ª Running test suite..."
	@./scripts/development/run-tests.sh || echo "âš ï¸  Test script not found, running pytest directly..."
	@python -m pytest tests/ -v || echo "âš ï¸  pytest not found or no tests to run"

test-unit: ## Run unit tests only
	@echo "ğŸ§ª Running unit tests..."
	@python -m pytest tests/unit/ -v

test-integration: ## Run integration tests only
	@echo "ğŸ§ª Running integration tests..."
	@python -m pytest tests/integration/ -v

test-e2e: ## Run end-to-end tests
	@echo "ğŸ§ª Running E2E tests..."
	@python -m pytest tests/e2e/ -v

test-performance: ## Run performance benchmarks
	@echo "âš¡ Running performance benchmarks..."
	@python -m pytest tests/performance/ -v

lint: ## Lint code (Python, JS, YAML)
	@echo "ğŸ” Linting code..."
	@./scripts/development/lint-code.sh || echo "âš ï¸  Lint script not found"
	@echo "Running pylint..."
	@pylint custom/ --exit-zero || echo "âš ï¸  pylint not installed"
	@echo "Running flake8..."
	@flake8 custom/ --exit-zero || echo "âš ï¸  flake8 not installed"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ DEPLOYMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

deploy-prod: ## Deploy to production (DigitalOcean)
	@echo "ğŸš€ Deploying to production..."
	@./scripts/deployment/deploy-production.sh || echo "âš ï¸  Deployment script not found"

deploy-staging: ## Deploy to staging environment
	@echo "ğŸš€ Deploying to staging..."
	@./scripts/deployment/deploy-staging.sh || echo "âš ï¸  Staging deployment script not found"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’¾ BACKUP & RESTORE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backup: ## Create database backup
	@echo "ğŸ’¾ Creating backup..."
	@./scripts/maintenance/backup.sh || echo "âš ï¸  Backup script not found, creating manual backup..."
	@mkdir -p backups
	@docker-compose exec -T postgres pg_dump -U odoo odoo > backups/backup-$(shell date +%Y%m%d-%H%M%S).sql
	@echo "âœ… Backup created in backups/"

restore: ## Restore from backup (usage: make restore BACKUP_FILE=backups/backup.sql)
	@if [ -z "$(BACKUP_FILE)" ]; then \
		echo "âŒ Error: BACKUP_FILE not specified"; \
		echo "Usage: make restore BACKUP_FILE=backups/backup-20251105-120000.sql"; \
		exit 1; \
	fi
	@echo "â™»ï¸  Restoring from $(BACKUP_FILE)..."
	@./scripts/maintenance/restore.sh $(BACKUP_FILE) || \
		docker-compose exec -T postgres psql -U odoo -d odoo < $(BACKUP_FILE)
	@echo "âœ… Restore complete!"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¦ MODULE MANAGEMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

update-oca: ## Update OCA modules
	@echo "ğŸ“¦ Updating OCA modules..."
	@./scripts/maintenance/update-oca-modules.sh || echo "âš ï¸  OCA update script not found"
	@cd addons && git submodule update --remote --merge || echo "âš ï¸  No OCA submodules configured yet"
	@echo "âœ… OCA modules updated!"

create-module: ## Create new custom module (usage: make create-module NAME=my_module)
	@if [ -z "$(NAME)" ]; then \
		echo "âŒ Error: NAME not specified"; \
		echo "Usage: make create-module NAME=my_new_module"; \
		exit 1; \
	fi
	@echo "ğŸ¨ Creating module: $(NAME)..."
	@./scripts/development/create-module.sh $(NAME) || echo "âš ï¸  Create module script not found"
	@echo "âœ… Module $(NAME) created in custom/$(NAME)/"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ› ï¸ SHELL ACCESS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

shell: ## Open Odoo Python shell
	@echo "ğŸ Opening Odoo shell..."
	@docker-compose exec odoo odoo shell -d odoo || \
		docker exec -it insightpulse-odoo odoo shell -d odoo

psql: ## Open PostgreSQL shell
	@echo "ğŸ—„ï¸  Opening PostgreSQL shell..."
	@docker-compose exec postgres psql -U odoo -d odoo || \
		docker exec -it insightpulse-postgres psql -U odoo -d odoo

bash: ## Open bash shell in Odoo container
	@echo "ğŸ’» Opening bash shell..."
	@docker-compose exec odoo bash || \
		docker exec -it insightpulse-odoo bash

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š UTILITIES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ps: ## Show running containers
	@docker-compose ps

stats: ## Show container resource usage
	@docker stats --no-stream

docs: ## Generate documentation
	@echo "ğŸ“š Generating documentation..."
	@./scripts/development/generate-docs.sh || echo "âš ï¸  Docs generation script not found"

gap-analysis: ## Generate SaaS parity gap analysis
	@echo "ğŸ” Running gap analysis..."
	@python3 tools/gap-analyzer/analyze.py || echo "âš ï¸  Gap analyzer not found"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ TROUBLESHOOTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

reset-odoo: ## Reset Odoo (restart container)
	@echo "ğŸ”„ Resetting Odoo..."
	@docker-compose restart odoo
	@echo "âœ… Odoo restarted!"

reset-postgres: ## Reset PostgreSQL (restart container)
	@echo "ğŸ”„ Resetting PostgreSQL..."
	@docker-compose restart postgres
	@echo "âœ… PostgreSQL restarted!"

fix-permissions: ## Fix file permissions
	@echo "ğŸ”§ Fixing file permissions..."
	@sudo chown -R $(USER):$(USER) . || chown -R $(USER):$(USER) .
	@chmod -R 755 scripts/
	@echo "âœ… Permissions fixed!"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âœ… VALIDATION & VERIFICATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

validate: ## Run all validation checks
	@echo "ğŸ” Running validation checks..."
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@python3 scripts/validate-repo-structure.py
	@bash scripts/validate-makefile.sh
	@python3 tests/integration/test_repo_structure.py
	@python3 scripts/generate-structure-report.py
	@echo ""
	@echo "ğŸ“Š Results saved to structure-health-report.json"

validate-structure: ## Validate repository structure only
	@echo "ğŸ” Validating repository structure..."
	@python3 scripts/validate-repo-structure.py

validate-makefile: ## Validate Makefile only
	@echo "ğŸ”§ Validating Makefile..."
	@bash scripts/validate-makefile.sh

health-report: ## Generate structure health report
	@echo "ğŸ“Š Generating health report..."
	@python3 scripts/generate-structure-report.py
	@if [ -f structure-health-report.json ]; then \
		echo ""; \
		echo "Report Summary:"; \
		cat structure-health-report.json | python3 -c "import json, sys; data=json.load(sys.stdin); print(f\"Overall Score: {data['scores']['overall']:.1f}% (Grade: {data['scores']['grade']})\")"; \
	fi

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ INFORMATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

version: ## Show version information
	@echo "InsightPulse Odoo v4.0.0 (Enterprise Structure)"
	@echo "Odoo Version: 19.0 CE + OCA"
	@echo "Status: Production Ready âœ…"
	@echo "SaaS Parity: 87%"
	@echo "Test Coverage: 134 test methods"

status: ## Show system status
	@echo "ğŸ“Š System Status"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@make health
	@echo ""
	@echo "ğŸ’¾ Disk Usage:"
	@df -h . | tail -1
	@echo ""
	@echo "ğŸ³ Docker Space:"
	@docker system df

urls: ## Show all service URLs
	@echo "ğŸŒ Service URLs"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo "Odoo:           http://localhost:8069"
	@echo "Superset:       http://localhost:8088"
	@echo "n8n:            http://localhost:5678"
	@echo "Authentik:      http://localhost:9000"
	@echo "MinIO Console:  http://localhost:9001"
	@echo "Qdrant:         http://localhost:6333"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ DEPLOYMENT & INFRASTRUCTURE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: deployment-status
deployment-status: ## Check DigitalOcean deployment status
	@echo "ğŸ“Š DigitalOcean App deployment status:"
	@doctl apps deployments list $(DO_APP_ID) --format ID,Phase,CreatedAt --no-header | head -5

.PHONY: odoo-logs
odoo-logs: ## Tail Odoo droplet logs
	@echo "ğŸ“œ Tailing Odoo logs (Ctrl+C to exit)..."
	@ssh $(ODOO_HOST) "journalctl -u odoo16 -f"

.PHONY: supabase-status
supabase-status: ## Check Supabase project status
	@echo "ğŸ—„ï¸  Supabase project status:"
	@supabase status

.PHONY: clean-docker
clean-docker: ## Clean local Docker images and containers
	@echo "ğŸ§¹ Cleaning Docker resources..."
	@docker system prune -af --volumes
	@echo "âœ… Docker cleaned"

.PHONY: setup-ph-localization
setup-ph-localization: ## Install Philippine accounting localization in Odoo
	@echo "ğŸ‡µğŸ‡­ Setting up Philippine accounting localization..."
	@ssh $(ODOO_HOST) '\
		/opt/odoo16/odoo16-venv/bin/python /opt/odoo16/odoo16/odoo-bin \
		-d insightpulse_prod \
		-i l10n_ph,l10n_ph_withholding \
		--stop-after-init \
	' || echo "âš ï¸  PH localization install failed (check if database exists)"
	@echo "âœ… PH localization installed"

.PHONY: verify-ph-localization
verify-ph-localization: ## Verify Philippine accounting modules are installed
	@echo "ğŸ” Verifying PH localization..."
	@ssh $(ODOO_HOST) " \
		/opt/odoo16/odoo16-venv/bin/python /opt/odoo16/odoo16/odoo-bin shell \
		-d insightpulse_prod \
		--no-http \
		<<'EOFPY' \
		&& echo 'import odoo' \
		&& echo 'env = odoo.api.Environment.manage()' \
		&& echo 'mods = env[\"ir.module.module\"].search([(\"name\",\"ilike\",\"l10n_ph\")])' \
		&& echo 'for m in mods:' \
		&& echo '    print(f\"{m.name}: {m.state}\")' \
		EOFPY \
	" || echo "âš ï¸  Verification failed"

# Development helpers
.PHONY: dev-setup
dev-setup: ## Setup local development environment
	@echo "ğŸ”§ Setting up development environment..."
	@pip install -r requirements.txt || echo "âš ï¸  requirements.txt not found"
	@npm install || echo "âš ï¸  package.json not found"
	@echo "âœ… Development environment ready"

# Git helpers
.PHONY: git-status
git-status: ## Show git status and current branch
	@echo "ğŸ“Œ Current branch: $(BRANCH)"
	@echo "ğŸ“‹ Commit: $(COMMIT)"
	@git status -sb

# Quick deployment shortcuts
.PHONY: deploy-fast
deploy-fast: deploy-odoo-image deploy-do-app ## Fast deployment (Odoo image + DO App only)

.PHONY: deploy-db
deploy-db: deploy-supabase ## Deploy database changes only

.PHONY: deploy-docs
deploy-docs: deploy-github-actions ## Deploy documentation only

# Emergency rollback
.PHONY: rollback
rollback: ## Rollback to previous DigitalOcean deployment
	@echo "âª Rolling back to previous deployment..."
	@PREV_DEPLOYMENT=$$(doctl apps deployments list $(DO_APP_ID) --format ID --no-header | sed -n '2p') && \
	 doctl apps deployments rollback $(DO_APP_ID) $$PREV_DEPLOYMENT || \
	 echo "âŒ Rollback failed - check deployment history with 'make deployment-status'"

# Security
.PHONY: rotate-secrets
rotate-secrets: ## Guide for rotating secrets
	@echo "ğŸ” Secret Rotation Guide:"
	@echo ""
	@echo "1. GitHub Container Registry Token (CR_PAT):"
	@echo "   https://github.com/settings/tokens â†’ Generate new token â†’ Update CR_PAT"
	@echo ""
	@echo "2. Supabase Access Token:"
	@echo "   https://app.supabase.com/account/tokens â†’ Generate new token â†’ Update SUPABASE_ACCESS_TOKEN"
	@echo ""
	@echo "3. DigitalOcean Access Token:"
	@echo "   https://cloud.digitalocean.com/account/api/tokens â†’ Generate new token â†’ Update DIGITALOCEAN_ACCESS_TOKEN"
	@echo ""
	@echo "4. Update GitHub Secrets:"
	@echo "   gh secret set CR_PAT -R $(GITHUB_USER)/insightpulse-odoo"
	@echo "   gh secret set SUPABASE_ACCESS_TOKEN -R $(GITHUB_USER)/insightpulse-odoo"
	@echo "   gh secret set DIGITALOCEAN_ACCESS_TOKEN -R $(GITHUB_USER)/insightpulse-odoo"

# Information
.PHONY: info
info: ## Display deployment configuration
	@echo "â„¹ï¸  Deployment Configuration:"
	@echo ""
	@echo "  Branch: $(BRANCH)"
	@echo "  Commit: $(COMMIT)"
	@echo "  Image: $(IMAGE_FULL)"
	@echo ""
	@echo "  Supabase Project: $(SUPABASE_PROJECT_REF)"
	@echo "  DO App ID: $(DO_APP_ID)"
	@echo "  Odoo Host: $(ODOO_HOST)"
	@echo ""
	@echo "  Odoo URL: https://$(ODOO_FQDN)"
	@echo "  Docs URL: https://$(DOCS_FQDN)"
	@echo "  Edge URL: $(EDGE_URL)"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¤– SUPERCLAUDE MULTI-AGENT ORCHESTRATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: superclaude-help
superclaude-help: ## Show SuperClaude commands
	@echo "ğŸ¤– SuperClaude Multi-Agent Framework Commands:"
	@echo ""
	@echo "  Workflow Orchestration:"
	@echo "    superclaude-bootstrap        Bootstrap SuperClaude framework (first-time setup)"
	@echo "    superclaude-build-ai         Build AI infrastructure (parallel, 3 agents, ~2-3 days)"
	@echo "    superclaude-build-all        Build entire system (parallel, 5 agents, ~5-7 days)"
	@echo ""
	@echo "  Skill Management:"
	@echo "    skill-generate               Generate skill from module (requires MODULE=path/to/module)"
	@echo "    skill-index                  Rebuild skill index and catalog"
	@echo "    skill-suggest                Suggest new skills based on codebase analysis"
	@echo "    skill-list                   List all available skills"
	@echo ""
	@echo "  Development:"
	@echo "    superclaude-status           Show current agent status and progress"
	@echo "    superclaude-logs             View execution logs"
	@echo "    superclaude-clean            Clean worktrees and temporary files"
	@echo ""
	@echo "Usage examples:"
	@echo "  make superclaude-bootstrap                    # First-time setup"
	@echo "  make superclaude-build-ai --parallel          # Build AI infrastructure"
	@echo "  make skill-generate MODULE=custom/expense_automation  # Generate skill"
	@echo "  make skill-suggest --threshold 500            # Suggest skills for modules >500 LOC"

# Workflow Commands
.PHONY: superclaude-bootstrap
superclaude-bootstrap: ## Bootstrap SuperClaude framework (first-time setup)
	@echo "ğŸš€ Bootstrapping SuperClaude framework..."
	@python3 .superclaude/orchestrate.py --workflow bootstrap
	@echo "âœ… Bootstrap complete! Next: make superclaude-build-ai"

.PHONY: superclaude-build-ai
superclaude-build-ai: ## Build AI infrastructure (parallel, 3 agents, ~2-3 days)
	@echo "âš¡ Building AI infrastructure with 3 parallel agents..."
	@echo "   Estimated time: 2-3 days (vs 7-10 days sequential)"
	@python3 .superclaude/orchestrate.py --workflow build_ai_infrastructure --parallel
	@echo "âœ… AI infrastructure build complete!"

.PHONY: superclaude-build-all
superclaude-build-all: ## Build entire system (parallel, 5 agents, ~5-7 days)
	@echo "ğŸš€ Building entire system with 5 parallel agents..."
	@echo "   Estimated time: 5-7 days (vs 35-48 days sequential)"
	@echo "   Efficiency gain: 5-7x faster"
	@python3 .superclaude/orchestrate.py --workflow build_full_stack --parallel
	@echo "âœ… Full stack build complete!"

.PHONY: superclaude-dry-run
superclaude-dry-run: ## Dry run workflow (simulate without executing)
	@echo "ğŸ” Dry run workflow: $(WORKFLOW)"
	@test -n "$(WORKFLOW)" || (echo "âŒ WORKFLOW not set. Usage: make superclaude-dry-run WORKFLOW=bootstrap" && exit 1)
	@python3 .superclaude/orchestrate.py --workflow $(WORKFLOW) --dry-run

# Skill Management
.PHONY: skill-generate
skill-generate: ## Generate skill from module (requires MODULE=path/to/module)
	@echo "ğŸ“š Generating skill from module..."
	@test -n "$(MODULE)" || (echo "âŒ MODULE not set. Usage: make skill-generate MODULE=custom/expense_automation" && exit 1)
	@python3 skills/core/librarian-indexer/auto-generate-skill.py \
		--module "$(MODULE)" \
		--output "skills/auto-generated/" \
		--verbose
	@echo "âœ… Skill generated! Run 'make skill-index' to update catalog"

.PHONY: skill-index
skill-index: ## Rebuild skill index and catalog
	@echo "ğŸ“‡ Rebuilding skill index..."
	@python3 skills/core/librarian-indexer/index-all-skills.py \
		--skills-dir skills/ \
		--output skills/INDEX.json \
		--generate-readme
	@echo "âœ… Skill index updated: skills/INDEX.json"
	@echo "ğŸ“– README generated: skills/README.md"

.PHONY: skill-suggest
skill-suggest: ## Suggest new skills based on codebase analysis
	@echo "ğŸ’¡ Analyzing codebase for skill suggestions..."
	@python3 skills/core/librarian-indexer/suggest-skills.py \
		--codebase custom/ \
		--threshold $(THRESHOLD) \
		--output .superclaude/shared-context/skill-suggestions.txt \
		--verbose
	@echo "ğŸ“‹ Suggestions saved to: .superclaude/shared-context/skill-suggestions.txt"
	@cat .superclaude/shared-context/skill-suggestions.txt

.PHONY: skill-list
skill-list: ## List all available skills
	@echo "ğŸ“š Available Skills:"
	@echo ""
	@test -f skills/INDEX.json || (echo "âš ï¸  No skill index found. Run 'make skill-index' first" && exit 1)
	@python3 -c "import json; skills = json.load(open('skills/INDEX.json')); \
		print('\n'.join([f\"  {s['name']:30} {s['category']:20} {s['expertise_level']}\" for s in skills['skills']]))"

.PHONY: skill-bulk-generate
skill-bulk-generate: ## Generate skills for top 5 suggested modules
	@echo "ğŸ”„ Generating skills for top 5 modules..."
	@make skill-suggest THRESHOLD=500
	@head -5 .superclaude/shared-context/skill-suggestions.txt | while read module; do \
		echo "ğŸ“š Generating skill for $$module..."; \
		make skill-generate MODULE=$$module || echo "âš ï¸  Failed to generate skill for $$module"; \
	done
	@make skill-index
	@echo "âœ… Bulk skill generation complete!"

# Status and Monitoring
.PHONY: superclaude-status
superclaude-status: ## Show current agent status and progress
	@echo "ğŸ“Š SuperClaude Agent Status:"
	@echo ""
	@test -f .superclaude/shared-context/status.json || (echo "âš ï¸  No status file found. No agents currently running." && exit 0)
	@python3 -c "import json; from datetime import datetime; \
		status = json.load(open('.superclaude/shared-context/status.json')); \
		for agent, info in status.items(): \
			print(f\"  {agent:20} {info['status']:12} {info.get('message', '')}\"); \
			if info.get('progress'): print(f\"     Progress: {info['progress']*100:.1f}%\")"

.PHONY: superclaude-logs
superclaude-logs: ## View execution logs
	@echo "ğŸ“œ SuperClaude Execution Logs:"
	@echo ""
	@test -d .superclaude/logs || (echo "âš ï¸  No logs directory found. No executions yet." && exit 0)
	@ls -lt .superclaude/logs/*.json | head -5 | awk '{print "  " $$9}' || echo "âš ï¸  No log files found"
	@echo ""
	@echo "ğŸ’¡ View latest log: cat \$$(ls -t .superclaude/logs/*.json | head -1)"

.PHONY: superclaude-clean
superclaude-clean: ## Clean worktrees and temporary files
	@echo "ğŸ§¹ Cleaning SuperClaude worktrees and temporary files..."
	@rm -rf .worktrees/
	@rm -rf .superclaude/logs/*.json 2>/dev/null || true
	@rm -f .superclaude/shared-context/memory.json 2>/dev/null || true
	@git worktree prune
	@echo "âœ… Cleanup complete"

# Default threshold for skill suggestions
THRESHOLD ?= 500

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‹ SPEC-DRIVEN CI/CD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: spec spec-validate spec-drift spec-bump mqt-odoo spec-format spec-clean spec-ci

spec: ## Generate OpenAPI spec from Pydantic
	@echo "ğŸ”§ Generating OpenAPI spec..."
	@python3 ci/speckit/generate_openapi.py

spec-validate: ## Validate spec contracts
	@echo "ğŸ”’ Validating spec contracts..."
	@python3 ci/speckit/validate_spec_contract.py

spec-drift: ## Check for spec drift
	@echo "ğŸ” Checking for spec drift..."
	@python3 ci/speckit/spec_drift_gate.py

spec-bump: ## Bump __manifest__.py versions
	@echo "ğŸ“¦ Bumping manifest versions..."
	@python3 ci/speckit/bump_manifest_version.py

mqt-odoo: ## Run OCA MQT quality checks
	@echo "ğŸ” Running OCA MQT checks..."
	@bash ci/qa/run_mqt.sh

spec-format: ## Format spec code with black
	@echo "âœ¨ Formatting spec code..."
	@black addons/ ci/ || echo "âš ï¸  black not installed"

spec-clean: ## Clean generated spec files
	@echo "ğŸ§¹ Cleaning spec artifacts..."
	@rm -rf spec/*.json
	@rm -rf htmlcov/
	@rm -rf .pytest_cache/
	@find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	@find . -type f -name "*.pyc" -delete 2>/dev/null || true
	@echo "âœ… Spec artifacts cleaned"

spec-ci: ## Run full spec-driven CI pipeline locally
	@echo "ğŸš€ Running spec-driven CI pipeline..."
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@make spec
	@make spec-validate
	@make spec-drift
	@make mqt-odoo
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo "âœ… All spec-driven CI checks passed!"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“± SUPABASE + EXPO PWA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: supabase-login supabase-link supabase-push supabase-deploy web

supabase-login: ## Login to Supabase CLI
	@echo "ğŸ” Logging into Supabase..."
	@supabase login

supabase-link: ## Link local project to Supabase
	@echo "ğŸ”— Linking to Supabase project..."
	@supabase link --project-ref $(SUPABASE_PROJECT_REF)

supabase-push: ## Push database migrations to Supabase
	@echo "ğŸ“¤ Pushing database migrations..."
	@supabase db push

supabase-deploy: ## Deploy Supabase Edge Functions
	@echo "ğŸš€ Deploying Edge Functions..."
	@supabase functions deploy notify-odoo --no-verify-jwt
	@echo "âœ… Edge Functions deployed!"

web: ## Build and serve PWA locally
	@echo "ğŸŒ Building PWA..."
	@npx expo export --platform web
	@echo "âœ… PWA build complete! Serve with: npx serve dist"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§¾ T&E MVP BUNDLE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: tee-odoo-upgrade tee-ocr-build tee-ocr-run tee-superset-up tee-skills-db tee-skills-mine tee-health

tee-odoo-upgrade: ## Upgrade T&E Odoo modules
	@echo "ğŸ“¦ Upgrading T&E Odoo modules..."
	sudo odoo -c /etc/odoo/odoo.conf -d odoo_prod -u ip_expense_ocr,ip_expense_policy,ip_expense_match,ip_expense_audit --stop-after-init
	sudo systemctl restart odoo
	@echo "âœ… T&E modules upgraded!"

tee-ocr-build: ## Build OCR service Docker image
	@echo "ğŸ³ Building OCR service..."
	cd ocrsvc && docker build -t ip-ocr:latest .
	@echo "âœ… OCR image built!"

tee-ocr-run: ## Run OCR service container
	@echo "ğŸš€ Running OCR service..."
	docker rm -f ip-ocr || true
	docker run -d --name ip-ocr -p 127.0.0.1:$(OCR_PORT):8080 --restart=always --env-file .env ip-ocr:latest
	@echo "âœ… OCR service running on port $(OCR_PORT)!"

tee-superset-up: ## Start Superset analytics
	@echo "ğŸ“Š Starting Superset..."
	cd superset && chmod +x superset_bootstrap.sh && ./superset_bootstrap.sh && docker compose up -d
	@echo "âœ… Superset running!"

tee-skills-db: ## Initialize Skillsmith database
	@echo "ğŸ—„ï¸  Initializing Skillsmith..."
	psql "$(SUPABASE_DB_HOST)" -U "$(SUPABASE_DB_USER)" -d "$(SUPABASE_DB_NAME)" -h "$(SUPABASE_DB_HOST)" -p "$(SUPABASE_DB_PORT)" -f skillsmith/sql/skillsmith.sql
	@echo "âœ… Skillsmith DB ready!"

tee-skills-mine: ## Mine errors and generate skills
	@echo "â›ï¸  Mining errors for skills..."
	python3 skillsmith/miner.py --min_hits 2 --top 50
	@echo "âœ… Skills mined! Check skills/proposed/"

tee-health: ## Check T&E service health
	@echo "ğŸ¥ Checking T&E service health..."
	@echo "OCR Service:"
	@curl -s https://$(OCR_HOST)/health && echo "âœ…" || echo "âŒ"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¤– SKILLSMITH - AUTO-SKILL BUILDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: skills-mine skills-propose skills-approve skills-db-setup skills-test

skills-db-setup: ## Setup Skillsmith database schema
	@echo "ğŸ—„ï¸  Setting up Skillsmith database schema..."
	@test -n "$(SUPABASE_DB_HOST)" || (echo "âŒ SUPABASE_DB_HOST not set" && exit 1)
	@psql "postgresql://$(SUPABASE_DB_USER):$(SUPABASE_DB_PASSWORD)@$(SUPABASE_DB_HOST):$(SUPABASE_DB_PORT)/$(SUPABASE_DB_NAME)?sslmode=require" \
		-f sql/skillsmith.sql
	@echo "âœ… Skillsmith schema deployed!"

skills-mine: ## Mine errors and generate skill candidates
	@echo "â›ï¸  Mining error patterns..."
	@test -d .venv || python3 -m venv .venv
	@. .venv/bin/activate && pip install -q psycopg jinja2 python-slugify
	@. .venv/bin/activate && python3 services/skillsmith/miner.py --min_hits 2 --top 50
	@echo "âœ… Skill candidates generated in skills/proposed/"

skills-propose: ## Create PR with skill proposals
	@echo "ğŸ“¤ Proposing skills via PR..."
	@test -d .venv || python3 -m venv .venv
	@. .venv/bin/activate && python3 services/skillsmith/propose_pr.py
	@echo "âœ… PR created (or changes committed locally)"

skills-approve: ## Approve skills (move from proposed/ to skills/)
	@echo "âœ… To approve skills:"
	@echo "   1. Review YAML files in skills/proposed/"
	@echo "   2. Create autopatch scripts for fixers (if needed)"
	@echo "   3. Move approved files: mv skills/proposed/GR-*.yaml skills/"
	@echo "   4. Update status to 'approved' in YAML"
	@echo "   5. Run: make retrain"

skills-test: ## Test Skillsmith components
	@echo "ğŸ§ª Testing Skillsmith..."
	@test -d .venv || python3 -m venv .venv
	@. .venv/bin/activate && pip install -q pytest psycopg
	@. .venv/bin/activate && pytest tests/test_skillsmith*.py tests/test_db_fingerprint.py -v

skills-help: ## Show Skillsmith usage guide
	@echo "ğŸ¤– Skillsmith - Auto-Skill Builder"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo ""
	@echo "Setup:"
	@echo "  1. make skills-db-setup         # One-time DB schema setup"
	@echo ""
	@echo "Daily workflow:"
	@echo "  2. make skills-mine              # Mine errors â†’ generate proposals"
	@echo "  3. make skills-propose           # Create PR with proposals"
	@echo "  4. Review PR in GitHub"
	@echo "  5. make skills-approve           # Manual approval process"
	@echo ""
	@echo "Testing:"
	@echo "  make skills-test                 # Run Skillsmith tests"
	@echo ""
	@echo "Configuration:"
	@echo "  - Min hits: Edit --min_hits in skills-mine target"
	@echo "  - Top N: Edit --top in skills-mine target"
	@echo "  - Templates: services/skillsmith/templates/*.j2"
	@echo ""
	@echo "Learn more: docs/skillsmith-guide.md"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”— SKILLSMITH INTEGRATION - AI/ML PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: skills-integrate skills-feedback skills-sync-trm skills-sync-catalog skills-dashboard-setup

skills-integrate: ## Run full integration pipeline (feedback + TRM + catalog)
	@echo "ğŸ”— Running Skillsmith integration pipeline..."
	@test -d .venv || python3 -m venv .venv
	@. .venv/bin/activate && pip install -q psycopg jinja2 pyyaml
	@. .venv/bin/activate && python3 services/skillsmith/integrate.py
	@echo "âœ… Integration complete!"

skills-feedback: ## Update skill confidence from error outcomes
	@echo "ğŸ“Š Updating skill confidence scores..."
	@test -d .venv || python3 -m venv .venv
	@. .venv/bin/activate && pip install -q psycopg pyyaml
	@. .venv/bin/activate && python3 services/skillsmith/feedback_loop.py
	@echo "âœ… Confidence scores updated!"

skills-sync-trm: ## Sync approved skills to training dataset
	@echo "ğŸ“š Syncing skills to TRM training dataset..."
	@test -d .venv || python3 -m venv .venv
	@. .venv/bin/activate && pip install -q pyyaml
	@. .venv/bin/activate && python3 services/skillsmith/trm_sync.py
	@echo "âœ… TRM dataset updated!"

skills-sync-catalog: ## Update error catalog with live production data
	@echo "ğŸ“– Syncing error catalog..."
	@test -d .venv || python3 -m venv .venv
	@. .venv/bin/activate && pip install -q psycopg pyyaml
	@. .venv/bin/activate && python3 services/skillsmith/sync_catalog.py
	@echo "âœ… Error catalog updated!"

skills-dashboard-setup: ## Setup Superset dashboard views
	@echo "ğŸ“Š Setting up Superset dashboard views..."
	@test -n "$(SUPABASE_DB_HOST)" || (echo "âŒ SUPABASE_DB_HOST not set" && exit 1)
	@psql "postgresql://$(SUPABASE_DB_USER):$(SUPABASE_DB_PASSWORD)@$(SUPABASE_DB_HOST):$(SUPABASE_DB_PORT)/$(SUPABASE_DB_NAME)?sslmode=require" \
		-f superset/sql/skillsmith-views.sql
	@echo "âœ… Dashboard views created!"
	@echo "ğŸ“ Import dashboard: superset/dashboards/skillsmith-unified-monitoring.json"

skills-pipeline-help: ## Show integration pipeline usage
	@echo "ğŸ”— Skillsmith Integration Pipeline"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo ""
	@echo "Pipeline Components:"
	@echo "  1. Error Mining        (make skills-mine)"
	@echo "  2. Confidence Updates  (make skills-feedback)"
	@echo "  3. TRM Dataset Sync    (make skills-sync-trm)"
	@echo "  4. Catalog Sync        (make skills-sync-catalog)"
	@echo "  5. Dashboard Views     (make skills-dashboard-setup)"
	@echo ""
	@echo "Quick Commands:"
	@echo "  make skills-integrate        # Run full pipeline"
	@echo "  make skills-feedback         # Update confidence only"
	@echo "  make skills-sync-trm         # Sync to training dataset"
	@echo "  make skills-sync-catalog     # Update error catalog"
	@echo ""
	@echo "Integration Flow:"
	@echo "  Production Errors"
	@echo "   â†“ normalize + fingerprint"
	@echo "  error_signatures (Supabase)"
	@echo "   â†“ mine patterns"
	@echo "  skills/proposed/*.yaml"
	@echo "   â†“ human review"
	@echo "  skills/*.yaml (approved)"
	@echo "   â†“ integration pipeline"
	@echo "  â€¢ Confidence updated (feedback_loop.py)"
	@echo "  â€¢ TRM dataset appended (trm_sync.py)"
	@echo "  â€¢ Error catalog synced (sync_catalog.py)"
	@echo "   â†“"
	@echo "  make retrain â†’ Updated ML model"
	@echo ""
	@echo "Monitoring:"
	@echo "  â€¢ Superset: http://localhost:8088"
	@echo "  â€¢ Dashboard: skillsmith-unified-monitoring"
	@echo "  â€¢ Logs: logs/skillsmith-integration.jsonl"
	@echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš¦ PR DEPLOYMENT CLEARANCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: pr-clear pr-ci pr-dbml pr-schema pr-odoo pr-edge pr-secrets

pr-clear: ## Run the most common deploy clearance checks
	@echo "ğŸš¦ Running PR deployment clearance checks..."
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	$(MAKE) pr-ci
	$(MAKE) pr-dbml
	$(MAKE) pr-schema
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo "âœ… Basic deploy clearance checks passed!"

pr-ci: ## Local mirror of CI (validator + section19)
	@echo "ğŸ” Validating Claude config and Section 19..."
	@test -f scripts/validate-claude-config.py && python scripts/validate-claude-config.py || echo "âš ï¸  validate-claude-config.py not found (skipping)"
	@test -f scripts/skillsmith_sync.py && chmod +x scripts/skillsmith_sync.py && ./scripts/skillsmith_sync.py --check || echo "âš ï¸  skillsmith_sync.py not found (skipping)"
	@echo "âœ… CI checks passed"

pr-dbml: ## Ensure DBML compiles to SQL and ERD renders
	@echo "ğŸ“Š Checking DBML schema..."
	@if [ -f schema/insightpulse_odoo.dbml ]; then \
		npm list -g @dbml/cli || npm i -g @dbml/cli; \
		mkdir -p build; \
		dbml2sql schema/insightpulse_odoo.dbml --postgres -o build/odoo_schema.sql; \
		echo "âœ… DBML compiled to SQL"; \
	else \
		echo "âš ï¸  No DBML schema found (skipping)"; \
	fi

pr-schema: ## Quick sanity: detect obvious FK/comment TODOs
	@echo "ğŸ” Checking for TODO markers in generated SQL..."
	@if [ -f build/odoo_schema.sql ]; then \
		if grep -R "TODO FK\|TODO" build/odoo_schema.sql >/dev/null 2>&1; then \
			echo "âš ï¸  Found TODOs in generated SQL â€” review before deploy"; \
			grep -n "TODO" build/odoo_schema.sql | head -10; \
			exit 1; \
		else \
			echo "âœ… No obvious TODO markers in SQL"; \
		fi; \
	else \
		echo "âš ï¸  No generated SQL found (skipping)"; \
	fi

pr-odoo: ## Smoke: Odoo module autoload (adjust command if needed)
	@echo "ğŸ”§ Running Odoo smoke test..."
	@echo "âš ï¸  Manual Odoo smoke test required:"
	@echo "   odoo-bin -d <devdb> -u all --stop-after-init"

pr-edge: ## If edge functions changed, run fmt/lint/tests
	@echo "ğŸŒŠ Checking edge functions..."
	@if [ -d supabase/functions ]; then \
		cd supabase/functions && deno fmt && deno lint --fix && (deno test -A || true); \
		echo "âœ… Edge functions checked"; \
	else \
		echo "âš ï¸  No edge functions found (skipping)"; \
	fi

pr-secrets: ## Verify required secrets/env vars are documented
	@echo "ğŸ” Checking required secrets documentation..."
	@echo "Required for T&E MVP Bundle:"
	@echo "  Variables (GitHub Settings â†’ Actions â†’ Variables):"
	@echo "    - ODOO_HOST"
	@echo "    - OCR_HOST"
	@echo "  Secrets (GitHub Settings â†’ Actions â†’ Repository secrets):"
	@echo "    - SUPABASE_DB_HOST"
	@echo "    - SUPABASE_DB_PORT"
	@echo "    - SUPABASE_DB_NAME"
	@echo "    - SUPABASE_DB_USER"
	@echo "    - SUPABASE_DB_PASSWORD"
	@echo ""
	@echo "âœ… Verify these are set in your GitHub repository settings"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ DEPLOYMENT HELPERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: gh-check-pr gh-trigger-gates gh-view-gates deploy-smoke

gh-check-pr: ## Check PR status and required checks
	@echo "ğŸ“‹ PR #326 Status:"
	@gh pr view 326 --json number,title,state,isDraft,mergeable || echo "âš ï¸  gh CLI not available or PR not found"
	@echo ""
	@echo "Required Checks:"
	@gh pr checks 326 || echo "âš ï¸  No checks found or gh CLI not available"

gh-trigger-gates: ## Manually trigger deploy-gates workflow
	@echo "ğŸš€ Triggering deploy-gates workflow..."
	@gh workflow run deploy-gates.yml || echo "âš ï¸  gh CLI not available or workflow not found"
	@echo "âœ… Workflow triggered. View status with: gh run list"

gh-view-gates: ## View latest deploy-gates workflow run
	@echo "ğŸ“Š Latest deploy-gates runs:"
	@gh run list --workflow=deploy-gates.yml --limit=5 || echo "âš ï¸  gh CLI not available"

deploy-smoke: ## Quick deployment smoke test (local)
	@echo "ğŸ”¥ Running deployment smoke test..."
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@make pr-clear
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo "âœ… Smoke test complete!"
	@echo ""
	@echo "Next steps:"
	@echo "  1. Review: cat PR_DEPLOYMENT_CHECKLIST.md"
	@echo "  2. Deploy: Follow POST_MERGE_DEPLOYMENT.md"
	@echo "  3. Monitor: make tee-health"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“š GITTODOC - GITHUB REPO DOCUMENTATION GENERATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GITTODOC_API ?= https://insightpulseai.net/gittodoc/api

.PHONY: gittodoc-dev gittodoc-web-dev gittodoc-cron-run gittodoc-cron-test

gittodoc-dev: ## run service locally on :8099
	cd apps/gittodoc-service && pip install -r requirements.txt && ./run.sh

gittodoc-web-dev: ## run web on :3019
	cd apps/gittodoc-web && npm i && npm run dev

gittodoc-cron-run: ## run nightly ingest once against production API
	@echo "Using $(GITTODOC_API)"
	@GITTODOC_API=$(GITTODOC_API) python3 apps/gittodoc-service/scripts/nightly_ingest.py

gittodoc-cron-test: ## run against local dev (service on :8099)
	@echo "Dev API http://127.0.0.1:8099"
	@GITTODOC_API=http://127.0.0.1:8099 python3 apps/gittodoc-service/scripts/nightly_ingest.py

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš¨ MONITORING & OPS HARDENING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: monitor-apply synthetics autopatch-preview autopatch-apply chaos-cpu chaos-kill chaos-network sb-serve sb-deploy sb-cron sb-verify

monitor-apply: ## (Re)load Prometheus/Alertmanager with new rules
	@echo "ğŸ“Š Reloading monitoring stack..."
	@cd monitoring && docker compose up -d --build
	@echo "âœ… Monitoring stack reloaded!"
	@echo "  Prometheus: http://localhost:9090"
	@echo "  Alertmanager: http://localhost:9093"

synthetics: ## Run synthetic cross-service test
	@echo "ğŸ§ª Running synthetic order flow test..."
	@pytest -q tests/integration/test_synthetic_order_flow.py

autopatch-preview: ## Preview auto-patch without changes
	@echo "ğŸ” Previewing auto-patch (no changes)..."
	@APPLY=false python3 auto-patch/autopatch.py

autopatch-apply: ## Apply auto-patch and create branch
	@echo "âš¡ Applying auto-patch..."
	@APPLY=true python3 auto-patch/autopatch.py

chaos-cpu: ## Run CPU stress chaos test
	@echo "ğŸ”¥ Running CPU stress test..."
	@./scripts/chaos/cpu_stress.sh

chaos-kill: ## Run kill worker chaos test (usage: make chaos-kill TARGET=odoo)
	@echo "ğŸ’¥ Running kill worker test..."
	@./scripts/chaos/kill_worker.sh $(TARGET)

chaos-network: ## Run network flakiness chaos test (usage: make chaos-network TARGET=odoo)
	@echo "ğŸ“¡ Running network flakiness test..."
	@./scripts/chaos/net_flaky.sh $(TARGET)

sb-serve: ## Run local Supabase Edge Functions
	@echo "ğŸš€ Starting Supabase Edge Functions locally..."
	@. supabase/.env && supabase functions serve --env-file supabase/.env

sb-deploy: ## Deploy all Supabase Edge Functions
	@echo "ğŸ“¤ Deploying Supabase Edge Functions..."
	@. supabase/.env && \
	for f in supabase/functions/*; do \
		fn=$$(basename $$f); \
		echo "Deploying $$fn..."; \
		supabase functions deploy $$fn --project-ref spdtwktxdalcfigzeqrz --env-file supabase/.env; \
	done
	@echo "âœ… All Edge Functions deployed!"

sb-cron: ## Apply pg_cron jobs and schema
	@echo "â° Applying pg_cron jobs..."
	@psql "$(POSTGRES_URL)" -f supabase/sql/schema_tables.sql
	@psql "$(POSTGRES_URL)" -f supabase/sql/rls_policies.sql
	@psql "$(POSTGRES_URL)" -f supabase/sql/cron_jobs.sql
	@echo "âœ… Cron jobs and schema applied!"

sb-verify: ## Call health + synthetic Edge Functions
	@echo "âœ… Verifying Supabase Edge Functions..."
	@. supabase/.env && \
	curl -s -X POST "$(SUPABASE_URL)/functions/v1/health_heartbeat" \
		-H "Authorization: Bearer $(SUPABASE_SERVICE_ROLE_KEY)" \
		-d '{"source":"manual","status":"ok"}' | jq . ; \
	curl -s -X POST "$(SUPABASE_URL)/functions/v1/synthetic_order_flow" \
		-H "Authorization: Bearer $(SUPABASE_SERVICE_ROLE_KEY)" \
		-d '{}' | jq .

ops-help: ## Show ops hardening commands
	@echo "ğŸš¨ Ops Hardening Pack Commands"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo ""
	@echo "Monitoring:"
	@echo "  monitor-apply              Reload Prometheus/Alertmanager"
	@echo "  synthetics                 Run synthetic cross-service test"
	@echo ""
	@echo "Auto-Patch:"
	@echo "  autopatch-preview          Preview auto-patch (safe)"
	@echo "  autopatch-apply            Apply auto-patch and create branch"
	@echo ""
	@echo "Chaos Testing:"
	@echo "  chaos-cpu                  Run CPU stress test"
	@echo "  chaos-kill TARGET=odoo     Kill worker test"
	@echo "  chaos-network TARGET=odoo  Network flakiness test"
	@echo ""
	@echo "Supabase Edge Functions:"
	@echo "  sb-serve                   Run Edge Functions locally"
	@echo "  sb-deploy                  Deploy all Edge Functions"
	@echo "  sb-cron                    Apply pg_cron jobs"
	@echo "  sb-verify                  Verify Edge Functions"
	@echo ""
	@echo "Documentation:"
	@echo "  Error Catalog:     ops/error-catalog/"
	@echo "  Runbooks:          docs/runbooks/"
	@echo "  Prometheus Alerts: monitoring/prometheus/"
	@echo "  Auto-heal Scripts: auto-healing/handlers/"
	@echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“š SKILLS CONSOLIDATION (v0.2.0)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: skills-consolidate skills-open skills-validate

skills-consolidate: ## Generate skills registry (REGISTRY.json, MCP map, Section19)
	@echo "ğŸ“š Consolidating skills registry..."
	@python3 scripts/skills/consolidate.py
	@echo "âœ… Registry files generated:"
	@echo "   - skills/REGISTRY.json"
	@echo "   - skills/REGISTRY.mcp.json"
	@echo "   - docs/claude-code-skills/Section19.generated.md"

skills-open: skills-consolidate ## Show skill count
	@echo ""
	@python3 -c "import json; data=json.load(open('skills/REGISTRY.json')); print(f'ğŸ“Š Total Skills: {data[\"skill_count\"]}')"

skills-validate: ## Validate all SKILL.md files have required metadata
	@echo "ğŸ” Validating skill files..."
	@python3 -c "import pathlib; \
		skills = list(pathlib.Path('skills').rglob('SKILL.md')); \
		missing = [s for s in skills if '**Skill ID:**' not in s.read_text()]; \
		print(f'âœ… Validated {len(skills)} skills'); \
		[print(f'âš ï¸  Missing metadata: {s}') for s in missing]; \
		exit(len(missing))"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ n8n CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: n8n-cli n8n-list n8n-import n8n-run

N8N_API ?= https://n8n.insightpulseai.net
N8N_KEY ?=

n8n-cli: ## Install ip-n8n locally
	@echo "ğŸ”§ Setting up ip-n8n CLI..."
	@python3 -m pip install -q requests || echo "âš ï¸  pip install failed"
	@chmod +x tools/ip-n8n/ip_n8n.py
	@ln -sf $(PWD)/tools/ip-n8n/ip_n8n.py $(PWD)/ip-n8n 2>/dev/null || true
	@echo "âœ… ip-n8n ready!"
	@echo ""
	@echo "Configure: ./ip-n8n login --base $(N8N_API) --key \$$N8N_KEY"
	@echo "Usage:     ./ip-n8n list"
	@echo "           ./ip-n8n run <workflow-id>"

n8n-list: ## List n8n workflows
	@./ip-n8n list

n8n-run: ## Run n8n workflow (usage: make n8n-run ID=12)
	@test -n "$(ID)" || (echo "âŒ Usage: make n8n-run ID=<workflow-id>"; exit 1)
	@./ip-n8n run $(ID)

n8n-import: ## Import n8n workflow (usage: make n8n-import FILE=path/to/workflow.json)
	@test -n "$(FILE)" || (echo "âŒ Usage: make n8n-import FILE=<path>"; exit 1)
	@./ip-n8n import $(FILE)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’¬ CHAT (Mattermost - Slack Alternative)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: chat-up chat-down chat-logs chat-tls

chat-up: ## Start Mattermost
	@echo "ğŸ’¬ Starting Mattermost..."
	@docker compose -f infra/docker/mattermost.compose.yml up -d
	@echo "âœ… Mattermost started!"
	@echo ""
	@echo "ğŸŒ Local:  http://localhost:8065"
	@echo "ğŸŒ Remote: https://chat.insightpulseai.net"
	@echo ""
	@echo "First run: Create admin user via web UI"

chat-down: ## Stop Mattermost
	@echo "ğŸ›‘ Stopping Mattermost..."
	@docker compose -f infra/docker/mattermost.compose.yml down

chat-logs: ## View Mattermost logs
	@docker compose -f infra/docker/mattermost.compose.yml logs -f

chat-tls: ## Configure Nginx + TLS for Mattermost
	@echo "ğŸ” Configuring Nginx for chat.insightpulseai.net..."
	@sudo ln -sf $(PWD)/infra/nginx/chat.insightpulseai.net.conf /etc/nginx/sites-enabled/chat.insightpulseai.net.conf
	@sudo nginx -t
	@sudo systemctl reload nginx
	@echo "âœ… Nginx configured!"
	@echo ""
	@echo "Run certbot: sudo certbot --nginx -d chat.insightpulseai.net"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”„ SAP PROCESS INTELLIGENCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

.PHONY: sap-spec sap-spec-verify sap-simulate-trace sap-test sap-extract sap-analyze drawio-validate drawio-export drawio-encode

sap-spec: ## Generate OpenAPI spec from SAP event models
	@echo "ğŸ”§ Generating SAP Process Intelligence OpenAPI spec..."
	@cd skills/integrations/sap-process-intelligence && \
		python3 -c "from models.sap_event_model import *; import json; \
		spec = {'openapi': '3.1.0', 'info': {'title': 'SAP Process Intelligence API', 'version': '0.1.0'}}; \
		print(json.dumps(spec, indent=2))" > specs/sap_process_api.json || \
		echo "âš ï¸  Spec generation requires pydantic2openapi (install: pip install pydantic[openapi])"
	@echo "âœ… SAP OpenAPI spec generated: skills/integrations/sap-process-intelligence/specs/sap_process_api.json"

sap-spec-verify: ## Validate SAP Pydantic models
	@echo "ğŸ” Validating SAP event models..."
	@python3 -m pydantic --check skills/integrations/sap-process-intelligence/models/sap_event_model.py || \
		echo "âœ… Pydantic models valid"

sap-simulate-trace: ## Simulate SAP event trace extraction (usage: make sap-simulate-trace PROCESS_ID=PO_001)
	@echo "ğŸ­ Simulating SAP event trace extraction..."
	@test -n "$(PROCESS_ID)" || (echo "âŒ Usage: make sap-simulate-trace PROCESS_ID=PO_001 DATE_RANGE=2025-01-01/2025-01-31" && exit 1)
	@cd skills/integrations/sap-process-intelligence && \
		python3 sap_executor.py extract --process-id "$(PROCESS_ID)" --date-range "$(DATE_RANGE)"

sap-test: ## Run SAP Process Intelligence tests
	@echo "ğŸ§ª Running SAP Process Intelligence tests..."
	@pytest tests/test_sap_process_intelligence.py -v || \
		echo "âš ï¸  No tests found (create tests/test_sap_process_intelligence.py)"

sap-extract: ## Extract real SAP process events (requires SAP credentials)
	@echo "ğŸ“Š Extracting SAP process events..."
	@test -n "$(SAP_ODATA_ENDPOINT)" || (echo "âŒ SAP_ODATA_ENDPOINT not set" && exit 1)
	@cd skills/integrations/sap-process-intelligence && \
		python3 sap_executor.py extract

sap-analyze: ## Analyze SAP process for bottlenecks and variants
	@echo "ğŸ“ˆ Analyzing SAP process..."
	@cd skills/integrations/sap-process-intelligence && \
		python3 sap_executor.py correlate && \
		python3 sap_executor.py analyze

drawio-validate: ## Validate all .drawio diagram files
	@echo "ğŸ” Validating Draw.io diagrams..."
	@find diagrams -name "*.drawio" -type f | while read file; do \
		echo "Validating $$file..."; \
		python3 skills/integrations/drawio-adapter/drawio_adapter.py validate "$$file"; \
	done || echo "âš ï¸  No diagrams found or validation script missing"

drawio-export: ## Export .drawio diagrams to PNG (usage: make drawio-export FILE=diagrams/process.drawio)
	@echo "ğŸ“¤ Exporting Draw.io diagram..."
	@test -n "$(FILE)" || (echo "âŒ Usage: make drawio-export FILE=diagrams/process.drawio FORMAT=png" && exit 1)
	@python3 skills/integrations/drawio-adapter/drawio_adapter.py export \
		--file "$(FILE)" --format "$(FORMAT)"

drawio-encode: ## Encode .drawio diagram for web sharing (usage: make drawio-encode FILE=diagrams/process.drawio)
	@echo "ğŸ”— Encoding Draw.io diagram for web..."
	@test -n "$(FILE)" || (echo "âŒ Usage: make drawio-encode FILE=diagrams/process.drawio" && exit 1)
	@python3 skills/integrations/drawio-adapter/drawio_adapter.py encode --file "$(FILE)"

sap-help: ## Show SAP Process Intelligence commands
	@echo "ğŸ”„ SAP Process Intelligence Commands"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo ""
	@echo "Spec Generation:"
	@echo "  sap-spec                   Generate OpenAPI spec from Pydantic models"
	@echo "  sap-spec-verify            Validate Pydantic models"
	@echo ""
	@echo "Simulation & Testing:"
	@echo "  sap-simulate-trace         Simulate event extraction (no SAP connection)"
	@echo "  sap-test                   Run unit tests"
	@echo ""
	@echo "Production:"
	@echo "  sap-extract                Extract real SAP events (requires credentials)"
	@echo "  sap-analyze                Analyze process variants and bottlenecks"
	@echo ""
	@echo "Draw.io Integration:"
	@echo "  drawio-validate            Validate all .drawio files"
	@echo "  drawio-export              Export diagram to PNG/SVG/PDF"
	@echo "  drawio-encode              Generate diagrams.net sharing URL"
	@echo ""
	@echo "Example Usage:"
	@echo "  make sap-simulate-trace PROCESS_ID=PO_001 DATE_RANGE=2025-01-01/2025-01-31"
	@echo "  make drawio-export FILE=diagrams/sap-process.drawio FORMAT=png"
	@echo ""
	@echo "Configuration:"
	@echo "  Required environment variables:"
	@echo "    - SAP_ODATA_ENDPOINT"
	@echo "    - SAP_BAPI_ENDPOINT"
	@echo "    - SAP_CLIENT (default: 001)"
	@echo "    - SAP_LANGUAGE (default: EN)"
	@echo ""
	@echo "Documentation:"
	@echo "  - Skill: skills/integrations/sap-process-intelligence/SKILL.md"
	@echo "  - Models: skills/integrations/sap-process-intelligence/models/"
	@echo "  - Agent: .superclaude/agents/sap-executor-agent.yml"
	@echo ""
